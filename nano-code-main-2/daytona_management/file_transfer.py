from pathlib import Path
from typing import List, Optional
import json
import os
from daytona_sdk.common.process import SessionExecuteRequest
from openai import uploads
from .config import PathConfig
import re


class FileTransfer:
    """æ–‡ä»¶ä¼ è¾“æ“ä½œç®¡ç†"""
    
    def __init__(self, sandbox):
        self.sandbox = sandbox
    
    # ç§»é™¤äº†æ—§çš„ upload_files æ–¹æ³•ï¼šä¸å†æ”¯æŒé›¶æ•£æ–‡ä»¶ä¸Šä¼ ï¼Œç»Ÿä¸€é€šè¿‡ upload_workspace_dir å¤„ç†

    def upload_workspace_dir(self, local_dir: str) -> int:
        """
        ä¸Šä¼ æœ¬åœ° workspace ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶åˆ°å®¹å™¨çš„ /workspace/tmp ä¸‹ï¼Œä¿æŒç›¸å¯¹è·¯å¾„ç»“æ„ã€‚
        ä¸ç­›é€‰ã€ä¸åˆ¤æ–­å­˜åœ¨æ€§ï¼ˆéå†ç°æœ‰æ–‡ä»¶ï¼‰ã€‚

        Returns: æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶æ•°é‡
        """
        root = Path(local_dir).expanduser()
        if not root.exists() or not root.is_dir():
            print(f"âš ï¸  å·¥ä½œåŒºç›®å½•æ— æ•ˆ: {local_dir}")
            return 0

        print(f"ğŸ“¤ ä¸Šä¼ å·¥ä½œåŒºç›®å½•: {root} â†’ {PathConfig.TMP_DIR}")
        count = 0
        for path in root.rglob("*"):
            if not path.is_file():
                continue
            rel = path.relative_to(root)
            # è§„èŒƒåŒ–ä¸ºå®¹å™¨è·¯å¾„
            remote_path = f"{PathConfig.TMP_DIR}/{str(rel).replace('\\\\','/').replace('\\','/')}"
            try:
                with open(path, 'rb') as f:
                    content = f.read()
                self.sandbox.fs.upload_file(content, remote_path)
                count += 1
                if count <= 5:
                    print(f"  âœ… {rel}")
            except Exception as e:
                print(f"  âŒ ä¸Šä¼ å¤±è´¥ {rel}: {e}")
        print(f"ğŸ“ å·¥ä½œåŒºä¸Šä¼ å®Œæˆï¼Œå…± {count} ä¸ªæ–‡ä»¶")
        return count

    # ç§»é™¤äº†æ—§çš„ process_json_file_and_uploadï¼šç»Ÿä¸€ä½¿ç”¨ process_json_and_rewrite_by_workspace

    # ç§»é™¤äº†æ—§çš„æœ¬åœ°èµ„æºåˆ¤æ–­/ä¸Šä¼ ç»†ç²’åº¦æ–¹æ³•ï¼šç»Ÿä¸€é€šè¿‡ upload_workspace_dir

    # ç§»é™¤äº†æ—§çš„åŸºäºé€ä¸ªæ–‡ä»¶ä¸Šä¼ å¹¶é‡å†™ JSON çš„æ–¹æ³•ï¼šç»Ÿä¸€ä»¥ workspace ä¸ºæ ¹è¿›è¡Œè·¯å¾„æ›¿æ¢

    def process_json_and_rewrite_by_workspace(self, json_file_path: str, workspace_local_dir: str) -> str:
        """
        åŸºäºæœ¬åœ° workspace æ ¹è·¯å¾„ï¼Œå°† JSON ä¸­å¼•ç”¨åˆ° workspace ä¸‹çš„è·¯å¾„é‡å†™ä¸ºå®¹å™¨è·¯å¾„ /workspace/tmp/<ç›¸å¯¹è·¯å¾„>ï¼Œ
        ä¸åšå­˜åœ¨æ€§åˆ¤æ–­ï¼›ç„¶åä¸Šä¼ é‡å†™åçš„ JSON åˆ°å®¹å™¨å¹¶è¿”å›è·¯å¾„ã€‚
        """
        local_path = Path(json_file_path)
        if not local_path.exists():
            raise FileNotFoundError(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        if not local_path.suffix.lower() == '.json':
            raise ValueError(f"è¾“å…¥æ–‡ä»¶å¿…é¡»æ˜¯JSONæ ¼å¼: {json_file_path}")

        with open(local_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        root = Path(workspace_local_dir).expanduser().resolve()

        def to_remote(p: str) -> str:
            if not isinstance(p, str) or not p.strip():
                return p
            lp = Path(os.path.expanduser(p))
            # ç›¸å¯¹è·¯å¾„ï¼šç›´æ¥æŒ‚åˆ° /workspace/tmp ä¸‹
            if not lp.is_absolute():
                rp = f"{PathConfig.TMP_DIR}/{p}"
                return rp.replace('\\\\','/').replace('\\','/')
            # ç»å¯¹è·¯å¾„ï¼šå¦‚æœåœ¨ workspace å†…ï¼Œåˆ™è½¬ç›¸å¯¹åå†æ‹¼
            try:
                rel = lp.resolve().relative_to(root)
                rp = f"{PathConfig.TMP_DIR}/{rel}"
                return rp.replace('\\\\','/').replace('\\','/')
            except Exception:
                # ä¸åœ¨ workspace ä¸‹çš„ï¼Œä¿æŒåŸå€¼ï¼ˆç”± Agent è‡ªè¡Œå¤„ç†ï¼‰
                return p

        # é‡å†™å·²çŸ¥å­—æ®µ
        try:
            exp = data.get('experimental_requirements') or {}
            repo = exp.get('code_repository_review') or {}
            if 'url' in repo and isinstance(repo['url'], str):
                repo['url'] = to_remote(repo['url'])
                exp['code_repository_review'] = repo
                data['experimental_requirements'] = exp
        except Exception:
            pass

        try:
            urls = data.get('urls')
            if isinstance(urls, list):
                for i, item in enumerate(urls):
                    if isinstance(item, dict) and 'url' in item and isinstance(item['url'], str):
                        item['url'] = to_remote(item['url'])
                        urls[i] = item
                data['urls'] = urls
        except Exception:
            pass

        resolved_name = f"{local_path.stem}-resolved.json"
        remote_json_path = f"{PathConfig.TMP_DIR}/{resolved_name}"
        content = json.dumps(data, ensure_ascii=False, indent=2)
        self.sandbox.fs.upload_file(content.encode('utf-8'), remote_json_path)
        print(f"âœ… ä¸Šä¼ é‡å†™åçš„JSON(å·¥ä½œåŒºè·¯å¾„æ›¿æ¢): {local_path.name} â†’ {remote_json_path}")
        return remote_json_path
    
    def download_results(self, session_id: str) -> List[str]:
        """
        ä¸‹è½½ç»“æœæ–‡ä»¶åˆ°æœ¬åœ°
        Args:
            session_id (str): ä¼šè¯ID
        Returns:
            List[str]: ä¸‹è½½åçš„æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½ç»“æœæ–‡ä»¶...")
        
        # åˆ›å»ºæœ¬åœ°ä¸‹è½½ç›®å½•
        download_dir = PathConfig.LOCAL_DOWNLOAD_DIR
        download_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            downloaded_files = []
            
            if session_id:
                # åˆ—å‡ºdownloadç›®å½•ä¸‹çš„ç»“æœæ–‡ä»¶
                list_cmd = f"find {PathConfig.DOWNLOAD_DIR} -maxdepth 1 -type f \\( -name '*.csv' -o -name '*.txt' -o -name '*.json' -o -name '*.html' -o -name '*.md' -o -name '*.png' -o -name '*.jpg' -o -name '*.py' -o -name '*.pdf' -o -name '*.xlsx' \\) 2>/dev/null || true"
                req = SessionExecuteRequest(command=list_cmd)
                result = self.sandbox.process.execute_session_command(session_id, req)
                
                if result.output.strip():
                    file_paths = result.output.strip().split('\n')
                    print(f"ğŸ¯ åœ¨downloadç›®å½•æ‰¾åˆ° {len(file_paths)} ä¸ªç»“æœæ–‡ä»¶")
                    
                    for remote_path in file_paths:
                        remote_path = remote_path.strip()
                        if remote_path and remote_path != "":
                            try:
                                # ä¸‹è½½æ–‡ä»¶
                                file_content = self.sandbox.fs.download_file(remote_path)
                                
                                # ä¿å­˜åˆ°æœ¬åœ°
                                local_filename = Path(remote_path).name
                                local_path = download_dir / local_filename
                                
                                with open(local_path, 'wb') as f:
                                    f.write(file_content)
                                
                                downloaded_files.append(str(local_path))
                                print(f"âœ… ä¸‹è½½æˆåŠŸ: {remote_path} â†’ {local_path}")
                                
                            except Exception as e:
                                print(f"âš ï¸  ä¸‹è½½å¤±è´¥ {remote_path}: {e}")
                else:
                    print("ğŸ“ downloadç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ç»“æœæ–‡ä»¶")
                
            if downloaded_files:
                print(f"ğŸ“ å…±ä¸‹è½½ {len(downloaded_files)} ä¸ªç»“æœæ–‡ä»¶åˆ°: {download_dir}")
                return downloaded_files
            else:
                print("ğŸ“ æœªæ‰¾åˆ°å¯ä¸‹è½½çš„ç»“æœæ–‡ä»¶")
                return []
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
            return []
    
    def collect_output_files(self, session_id: str, input_filenames: Optional[List[str]] = None, copy: bool = True):
        """
        æ”¶é›†AIç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶åˆ°downloadç›®å½•
        Args:
            session_id (str): ä¼šè¯ID
            input_filenames (Optional[List[str]]): è¾“å…¥æ–‡ä»¶ååˆ—è¡¨ï¼Œç”¨äºæ’é™¤
            copy (bool): Trueä¸ºå¤åˆ¶æ¨¡å¼ï¼ˆä¿ç•™åŸæ–‡ä»¶ï¼‰ï¼ŒFalseä¸ºç§»åŠ¨æ¨¡å¼
        """
        operation_name = "å¤åˆ¶" if copy else "ç§»åŠ¨"
        print(f"ğŸ“¦ æ”¶é›†è¾“å‡ºæ–‡ä»¶({operation_name}æ¨¡å¼)...")

        # å…ˆå°è¯•é€šè¿‡ manifest (agent_output.json) ç²¾ç¡®æ”¶é›†
        try:
            collected = self._collect_by_manifest(session_id, input_filenames or [], copy)
            if collected > 0:
                print(f"âœ… åŸºäºmanifestæ”¶é›† {collected} ä¸ªäº§ç‰©")
                return
            else:
                print("â„¹ï¸ æœªé€šè¿‡manifestæ‰¾åˆ°äº§ç‰©ï¼Œå›é€€ä¸ºç›®å½•æ‰«ææ¨¡å¼")
        except Exception as e:
            print(f"âš ï¸  manifestæ”¶é›†å¤±è´¥ï¼Œå›é€€æ‰«æ: {e}")
        
        find_cmd = f"find {PathConfig.TMP_DIR} -type f -not -path '*/.*' -not -path '*/__pycache__/*' -not -path '*/venv/*' 2>/dev/null"
        req = SessionExecuteRequest(command=find_cmd)
        result = self.sandbox.process.execute_session_command(session_id, req)
        
        if result.output.strip():
            all_files = result.output.strip().split('\n')
            
            input_filenames = input_filenames or []
            ai_generated_files = []
            
            for file_path in all_files:
                file_path = file_path.strip()
                if file_path:
                    filename = file_path.split('/')[-1]
                    
                    # è·³è¿‡è¾“å…¥æ–‡ä»¶
                    if filename in input_filenames:
                        continue
                    
                    # æ’é™¤å…‹éš†çš„Gitä»“åº“ç›®å½•
                    if 'repos/' in file_path or '/repos/' in file_path:
                        continue
                    
                    # æ›´å¼ºçš„Gitä»“åº“æ£€æµ‹ï¼šåªä¿ç•™æ˜ç¡®çš„AIè¾“å‡ºæ–‡ä»¶
                    # å¦‚æœæ–‡ä»¶åœ¨ä¸€ä¸ªçœ‹èµ·æ¥åƒGitä»“åº“çš„ç›®å½•ä¸­ï¼ˆæœ‰å¸¸è§çš„ä»“åº“æ–‡ä»¶ï¼‰ï¼Œè·³è¿‡å®ƒ
                    path_parts = file_path.split('/')
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€ä¸ªç›®å½•çº§åˆ«æœ‰å¸¸è§çš„Gitä»“åº“æ–‡ä»¶
                    file_dir = '/'.join(path_parts[:-1])  # æ–‡ä»¶æ‰€åœ¨ç›®å½•
                    common_repo_files = ['README.md', 'LICENSE', 'setup.py', 'pyproject.toml', 'package.json', '.gitignore']
                    
                    # ç®€å•ç­–ç•¥ï¼šå¦‚æœæ–‡ä»¶åæ˜¯å¸¸è§çš„æºç æ–‡ä»¶ç±»å‹ï¼Œä¸”ä¸æ˜¯æ˜ç¡®çš„åˆ†æè¾“å‡ºï¼Œè·³è¿‡
                    if (filename.endswith(('.py', '.js', '.ts', '.java', '.go', '.rs', '.cpp', '.c', '.h')) 
                        and not filename.startswith('architecture_analysis_') 
                        and not filename.startswith('analysis_')
                        and not filename.startswith('project_structure')
                        and not filename.startswith('application_flow')):
                        continue
                    
                    # ä¿ç•™matplotlibç”Ÿæˆçš„PNGæ–‡ä»¶
                    if filename.endswith('.png') and (
                        filename.startswith('project_structure') or 
                        filename.startswith('application_flow') or 
                        'analysis' in filename):
                        # è¿™äº›æ˜¯AIç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶ï¼Œä¿ç•™
                        pass
                    
                    # æ’é™¤å¸¸è§çš„ä»“åº“é…ç½®æ–‡ä»¶
                    if filename in ['README.md', 'LICENSE', 'setup.py', 'pyproject.toml', 'package.json', '.gitignore', 'Cargo.toml', 'go.mod']:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
                    should_exclude = False
                    for pattern in PathConfig.EXCLUDE_PATTERNS:
                        if pattern in filename or pattern in file_path:
                            should_exclude = True
                            break
                    
                    if not should_exclude:
                        ai_generated_files.append(file_path)
            
            if ai_generated_files:
                print(f"ğŸ” å‘ç° {len(ai_generated_files)} ä¸ªç”Ÿæˆæ–‡ä»¶")
                
                processed_count = 0
                for file_path in ai_generated_files:
                    filename = file_path.split('/')[-1]
                    download_path = f"{PathConfig.DOWNLOAD_DIR}/{filename}"
                    
                    # æ ¹æ®copyå‚æ•°é€‰æ‹©æ“ä½œå‘½ä»¤
                    if copy:
                        op_cmd = f"cp -f '{file_path}' '{download_path}'"
                        action_verb = "å¤åˆ¶"
                    else:
                        op_cmd = f"mv '{file_path}' '{download_path}'"
                        action_verb = "ç§»åŠ¨"
                    
                    req = SessionExecuteRequest(command=op_cmd)
                    op_result = self.sandbox.process.execute_session_command(session_id, req)
                    
                    if op_result.exit_code == 0:
                        print(f"âœ… {action_verb}ç”Ÿæˆæ–‡ä»¶: {filename}")
                        processed_count += 1
                    else:
                        print(f"âš ï¸  {action_verb}å¤±è´¥: {filename}")
                
                if processed_count > 0:
                    print(f"ğŸ“ æˆåŠŸ{operation_name} {processed_count} ä¸ªè¾“å‡ºæ–‡ä»¶åˆ° {PathConfig.DOWNLOAD_DIR}")
                else:
                    print(f"âš ï¸  æœªèƒ½{operation_name}ä»»ä½•è¾“å‡ºæ–‡ä»¶")
            else:
                print("ğŸ“ æœªå‘ç°æ–°åˆ›å»ºçš„æ–‡ä»¶")
        else:
            print("ğŸ“ tmpç›®å½•ä¸­æœªå‘ç°æ–‡ä»¶")
    
    # ======== Manifestä¼˜å…ˆæ”¶é›†å®ç° ========
    def _collect_by_manifest(self, session_id: str, input_filenames: List[str], copy: bool) -> int:
        """ä¼˜å…ˆæ ¹æ® /workspace/tmp/agent_output.json çš„ artifacts æ¸…å•æ”¶é›†äº§ç‰©"""
        manifest_path = f"{PathConfig.TMP_DIR}/agent_output.json"
        if not self._path_exists(session_id, manifest_path):
            return 0

        manifest_text = self._read_text(session_id, manifest_path)
        if not manifest_text:
            return 0

        try:
            data = json.loads(manifest_text)
        except Exception:
            return 0

        artifacts = data.get("artifacts") or []
        if not isinstance(artifacts, list) or not artifacts:
            return 0

        processed = 0
        seen = set()
        for a in artifacts:
            for src in self._resolve_artifact_paths(a):
                if not src:
                    continue
                if not self._path_exists(session_id, src):
                    continue

                filename = os.path.basename(src)
                if filename in input_filenames:
                    continue
                if not self._is_allowed_output(filename):
                    continue
                if filename in seen:
                    continue

                dst = f"{PathConfig.DOWNLOAD_DIR}/{filename}"
                if self._copy_or_move(session_id, src, dst, copy):
                    processed += 1
                    seen.add(filename)

        return processed

    def _resolve_artifact_paths(self, artifact: dict) -> List[str]:
        """æ ¹æ® artifact å­—æ®µæ¨å¯¼æ½œåœ¨çš„è¿œç¨‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨"""
        paths: List[str] = []
        img = artifact.get("image")
        if isinstance(img, str) and self._looks_like_path(img):
            paths.append(img)

        f = artifact.get("file")
        if isinstance(f, str) and self._looks_like_path(f):
            paths.append(f)

        t = artifact.get("table")
        if isinstance(t, str) and self._looks_like_path(t):
            paths.append(t)

        title = artifact.get("title")
        if isinstance(title, str) and title:
            paths.append(f"{PathConfig.TMP_DIR}/{title}")

        dedup = []
        seen = set()
        for p in paths:
            if p not in seen:
                seen.add(p)
                dedup.append(p)
        return dedup

    def _is_allowed_output(self, filename: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ˜¯å…è®¸çš„è¾“å‡ºç±»å‹
        """
        ext = os.path.splitext(filename)[1].lower()
        return ext in {".csv", ".txt", ".json", ".html", ".md", ".png", ".jpg", ".py", ".pdf", ".xlsx"}

    def _copy_or_move(self, session_id: str, src: str, dst: str, copy: bool) -> bool:
        """
        å¤åˆ¶æˆ–ç§»åŠ¨æ–‡ä»¶
        """
        cmd = f"cp -f '{src}' '{dst}'" if copy else f"mv '{src}' '{dst}'"
        req = SessionExecuteRequest(command=cmd)
        result = self.sandbox.process.execute_session_command(session_id, req)
        if result and getattr(result, 'exit_code', 1) == 0:
            print(f"âœ… {'å¤åˆ¶' if copy else 'ç§»åŠ¨'}: {src} â†’ {dst}")
            return True
        print(f"âš ï¸  {'å¤åˆ¶' if copy else 'ç§»åŠ¨'}å¤±è´¥: {src}")
        return False

    def _path_exists(self, session_id: str, path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨
        """
        cmd = f"test -f '{path}' && echo YES || echo NO"
        req = SessionExecuteRequest(command=cmd)
        result = self.sandbox.process.execute_session_command(session_id, req)
        out = (result.output or "").strip().upper()
        return out.endswith("YES")

    def _read_text(self, session_id: str, path: str) -> str:
        """
        è¯»å–æ–‡ä»¶å†…å®¹
        """
        cmd = f"cat '{path}' 2>/dev/null || true"
        req = SessionExecuteRequest(command=cmd)
        result = self.sandbox.process.execute_session_command(session_id, req)
        return (result.output or "") if result else ""

    def _looks_like_path(self, value: str) -> bool:
        """
        æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦çœ‹èµ·æ¥åƒæ–‡ä»¶è·¯å¾„
        è·¯å¾„å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„ï¼ˆä»¥ '/' å¼€å¤´ï¼‰æˆ–åŒ…å« '/workspace/' çš„ç›¸å¯¹è·¯å¾„
        """
        return isinstance(value, str) and (value.startswith('/') or '/workspace/' in value)
